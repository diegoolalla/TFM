{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFM - An谩lisis de Dataset P煤blico\n",
    "\n",
    "**Autor:** [Tu nombre]\n",
    "\n",
    "**Fecha:** [Fecha]\n",
    "\n",
    "**Dataset:** [Nombre del dataset]\n",
    "\n",
    "---\n",
    "\n",
    "## Tabla de Contenidos\n",
    "\n",
    "1. [Introducci贸n](#1-introducci贸n)\n",
    "2. [Carga y Exploraci贸n de Datos](#2-carga-y-exploraci贸n-de-datos)\n",
    "3. [An谩lisis Descriptivo](#3-an谩lisis-descriptivo)\n",
    "4. [Transformaci贸n de Datos](#4-transformaci贸n-de-datos)\n",
    "5. [Modelizaci贸n Predictiva](#5-modelizaci贸n-predictiva)\n",
    "6. [Evaluaci贸n de Modelos](#6-evaluaci贸n-de-modelos)\n",
    "7. [Discusi贸n de Resultados](#7-discusi贸n-de-resultados)\n",
    "8. [Conclusiones](#8-conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducci贸n\n",
    "\n",
    "### 1.1 Descripci贸n del Problema\n",
    "\n",
    "[Describe el problema que se va a abordar y el contexto del dataset]\n",
    "\n",
    "### 1.2 Objetivos\n",
    "\n",
    "- Objetivo principal: [Define el objetivo principal del an谩lisis]\n",
    "- Objetivos espec铆ficos:\n",
    "  - [Objetivo 1]\n",
    "  - [Objetivo 2]\n",
    "  - [Objetivo 3]\n",
    "\n",
    "### 1.3 Dataset\n",
    "\n",
    "- **Fuente:** [URL o referencia del dataset]\n",
    "- **Descripci贸n:** [Breve descripci贸n del dataset]\n",
    "- **N煤mero de instancias:** [N]\n",
    "- **N煤mero de caracter铆sticas:** [M]\n",
    "- **Variable objetivo:** [Variable de inter茅s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci贸n de librer铆as\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "# Configuraci贸n\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploraci贸n de Datos\n",
    "\n",
    "### 2.1 Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "# NOTA: Reemplaza 'your_dataset.csv' con el nombre real de tu archivo\n",
    "# df = pd.read_csv('../data/raw/your_dataset.csv')\n",
    "\n",
    "# Ejemplo con dataset de prueba (Iris)\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "print(f\"Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Primeras Observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeras filas\n",
    "display(df.head())\n",
    "\n",
    "# Informaci贸n general\n",
    "print(\"\\nInformaci贸n del dataset:\")\n",
    "df.info()\n",
    "\n",
    "# Estad铆sticas descriptivas\n",
    "print(\"\\nEstad铆sticas descriptivas:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calidad de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores nulos\n",
    "print(\"Valores nulos por columna:\")\n",
    "null_counts = df.isnull().sum()\n",
    "null_percentages = (null_counts / len(df)) * 100\n",
    "null_df = pd.DataFrame({\n",
    "    'Nulos': null_counts,\n",
    "    'Porcentaje': null_percentages\n",
    "})\n",
    "display(null_df[null_df['Nulos'] > 0])\n",
    "\n",
    "# Duplicados\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nFilas duplicadas: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An谩lisis Descriptivo\n",
    "\n",
    "### 3.1 An谩lisis Univariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci贸n de variables num茅ricas\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(len(numeric_cols), 2, figsize=(15, 4*len(numeric_cols)))\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    # Histograma\n",
    "    axes[idx, 0].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx, 0].set_title(f'Distribuci贸n de {col}')\n",
    "    axes[idx, 0].set_xlabel(col)\n",
    "    axes[idx, 0].set_ylabel('Frecuencia')\n",
    "    \n",
    "    # Boxplot\n",
    "    axes[idx, 1].boxplot(df[col].dropna())\n",
    "    axes[idx, 1].set_title(f'Boxplot de {col}')\n",
    "    axes[idx, 1].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/univariate_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 An谩lisis de la Variable Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci贸n de la variable objetivo\n",
    "target_col = 'target'  # Reemplaza con tu variable objetivo\n",
    "\n",
    "if target_col in df.columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    if df[target_col].dtype in ['int64', 'object']:\n",
    "        # Variable categ贸rica\n",
    "        value_counts = df[target_col].value_counts()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        value_counts.plot(kind='bar')\n",
    "        plt.title(f'Distribuci贸n de {target_col}')\n",
    "        plt.xlabel(target_col)\n",
    "        plt.ylabel('Frecuencia')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%')\n",
    "        plt.title(f'Proporci贸n de {target_col}')\n",
    "    else:\n",
    "        # Variable continua\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(df[target_col], bins=30, edgecolor='black')\n",
    "        plt.title(f'Distribuci贸n de {target_col}')\n",
    "        plt.xlabel(target_col)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.boxplot(df[target_col])\n",
    "        plt.title(f'Boxplot de {target_col}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/visualizations/target_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 An谩lisis Multivariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci贸n\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlaci贸n')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Identificar correlaciones fuertes\n",
    "print(\"\\nCorrelaciones m谩s fuertes (|r| > 0.7):\")\n",
    "high_corr = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr.append((\n",
    "                correlation_matrix.columns[i],\n",
    "                correlation_matrix.columns[j],\n",
    "                correlation_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "if high_corr:\n",
    "    for var1, var2, corr in high_corr:\n",
    "        print(f\"{var1} - {var2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"No se encontraron correlaciones fuertes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot (para datasets peque帽os)\n",
    "if len(numeric_cols) <= 6 and len(df) <= 1000:\n",
    "    if target_col in df.columns:\n",
    "        sns.pairplot(df, hue=target_col, diag_kind='kde', corner=True)\n",
    "        plt.savefig('../results/visualizations/pairplot.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Dataset demasiado grande para pairplot completo. Selecciona variables espec铆ficas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transformaci贸n de Datos\n",
    "\n",
    "### 4.1 Tratamiento de Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia para transformaciones\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Estrategias de imputaci贸n\n",
    "# Ejemplo: imputar con la mediana para variables num茅ricas\n",
    "numeric_cols_with_nulls = df_clean[numeric_cols].columns[df_clean[numeric_cols].isnull().any()].tolist()\n",
    "\n",
    "for col in numeric_cols_with_nulls:\n",
    "    median_value = df_clean[col].median()\n",
    "    df_clean[col].fillna(median_value, inplace=True)\n",
    "    print(f\"Columna '{col}': imputada con mediana ({median_value:.2f})\")\n",
    "\n",
    "print(f\"\\nValores nulos despu茅s de la imputaci贸n: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Tratamiento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecci贸n de outliers usando IQR\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "print(\"Detecci贸n de outliers:\")\n",
    "for col in numeric_cols:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df_clean, col)\n",
    "    print(f\"{col}: {len(outliers)} outliers detectados (rango: [{lower:.2f}, {upper:.2f}])\")\n",
    "\n",
    "# NOTA: Decide si eliminar o transformar outliers seg煤n el contexto\n",
    "# df_clean = df_clean[...] # Filtrar outliers si es necesario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Codificaci贸n de Variables Categ贸ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar variables categ贸ricas\n",
    "categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Variables categ贸ricas: {categorical_cols}\")\n",
    "\n",
    "# Codificaci贸n (ajustar seg煤n necesidad)\n",
    "# One-Hot Encoding para variables con pocas categor铆as\n",
    "# Label Encoding para variables ordinales\n",
    "\n",
    "if categorical_cols:\n",
    "    # Ejemplo: One-Hot Encoding\n",
    "    df_encoded = pd.get_dummies(df_clean, columns=categorical_cols, drop_first=True)\n",
    "    print(f\"\\nDataset despu茅s de encoding: {df_encoded.shape}\")\n",
    "else:\n",
    "    df_encoded = df_clean.copy()\n",
    "    print(\"\\nNo hay variables categ贸ricas para codificar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Normalizaci贸n/Estandarizaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Separar caracter铆sticas y variable objetivo\n",
    "X = df_encoded.drop(target_col, axis=1)\n",
    "y = df_encoded[target_col]\n",
    "\n",
    "# Estandarizaci贸n (media=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X),\n",
    "    columns=X.columns,\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "print(f\"Caracter铆sticas estandarizadas: {X_scaled.shape}\")\n",
    "print(f\"\\nEstad铆sticas despu茅s de estandarizaci贸n:\")\n",
    "display(X_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Divisi贸n Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divisi贸n 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}\")\n",
    "print(f\"\\nDistribuci贸n en entrenamiento:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nDistribuci贸n en prueba:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelizaci贸n Predictiva\n",
    "\n",
    "### 5.1 Definici贸n de Modelos\n",
    "\n",
    "Implementaremos diferentes t茅cnicas de Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Diccionario de modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE, n_estimators=100),\n",
    "    'SVM': SVC(random_state=RANDOM_STATE, probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(f\"Modelos definidos: {len(models)}\")\n",
    "for name in models.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"Entrenando modelos\"):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validaci贸n cruzada\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Tiempo de entrenamiento\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results[name] = {\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    print(f\"{name}: CV Accuracy = {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Comparaci贸n Inicial de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'CV Mean Accuracy': [results[m]['cv_mean'] for m in results],\n",
    "    'CV Std': [results[m]['cv_std'] for m in results],\n",
    "    'Training Time (s)': [results[m]['training_time'] for m in results]\n",
    "}).sort_values('CV Mean Accuracy', ascending=False)\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "# Visualizar comparaci贸n\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(results_df['Model'], results_df['CV Mean Accuracy'], \n",
    "        yerr=results_df['CV Std'], capsize=5, alpha=0.7)\n",
    "plt.xlabel('Modelo')\n",
    "plt.ylabel('Accuracy (Validaci贸n Cruzada)')\n",
    "plt.title('Comparaci贸n de Modelos - Validaci贸n Cruzada')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/model_comparison_cv.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluaci贸n de Modelos\n",
    "\n",
    "### 6.1 M茅tricas de Evaluaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Calcular m茅tricas para cada modelo\n",
    "evaluation_results = []\n",
    "\n",
    "for name in results.keys():\n",
    "    y_pred = results[name]['predictions']\n",
    "    \n",
    "    # Calcular m茅tricas (ajustar average seg煤n el problema)\n",
    "    metrics = {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1-Score': f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    evaluation_results.append(metrics)\n",
    "\n",
    "evaluation_df = pd.DataFrame(evaluation_results).sort_values('F1-Score', ascending=False)\n",
    "display(evaluation_df)\n",
    "\n",
    "# Guardar resultados\n",
    "evaluation_df.to_csv('../results/metrics/model_evaluation.csv', index=False)\n",
    "print(\"\\nResultados guardados en: results/metrics/model_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Matrices de Confusi贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar los 3 mejores modelos\n",
    "top_models = evaluation_df.head(3)['Model'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(top_models), figsize=(15, 4))\n",
    "\n",
    "for idx, model_name in enumerate(top_models):\n",
    "    y_pred = results[model_name]['predictions']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                ax=axes[idx], cbar=False)\n",
    "    axes[idx].set_title(f'{model_name}\\nAccuracy: {evaluation_df[evaluation_df[\"Model\"]==model_name][\"Accuracy\"].values[0]:.4f}')\n",
    "    axes[idx].set_xlabel('Predicci贸n')\n",
    "    axes[idx].set_ylabel('Real')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Reportes de Clasificaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte detallado del mejor modelo\n",
    "best_model_name = evaluation_df.iloc[0]['Model']\n",
    "y_pred_best = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"Reporte de clasificaci贸n - {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Curvas ROC (para clasificaci贸n binaria/multiclase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Determinar n煤mero de clases\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "if n_classes == 2:\n",
    "    # Clasificaci贸n binaria\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for model_name in top_models:\n",
    "        model = trained_models[model_name]\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_score = model.predict_proba(X_test)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Curvas ROC - Comparaci贸n de Modelos')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig('../results/visualizations/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Clasificaci贸n multiclase ({n_classes} clases). Usar estrategia one-vs-rest para ROC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Importancia de Caracter铆sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para modelos basados en 谩rboles\n",
    "tree_based_models = ['Random Forest', 'Gradient Boosting', 'Decision Tree']\n",
    "\n",
    "for model_name in tree_based_models:\n",
    "    if model_name in trained_models:\n",
    "        model = trained_models[model_name]\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # Obtener importancias\n",
    "            importances = model.feature_importances_\n",
    "            feature_importance_df = pd.DataFrame({\n",
    "                'Feature': X_train.columns,\n",
    "                'Importance': importances\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            \n",
    "            # Visualizar top 15\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            top_features = feature_importance_df.head(15)\n",
    "            plt.barh(top_features['Feature'], top_features['Importance'])\n",
    "            plt.xlabel('Importancia')\n",
    "            plt.title(f'Top 15 Caracter铆sticas - {model_name}')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results/visualizations/feature_importance_{model_name.replace(\" \", \"_\").lower()}.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"\\nTop 10 caracter铆sticas - {model_name}:\")\n",
    "            display(feature_importance_df.head(10))\n",
    "            break  # Mostrar solo uno para no saturar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Optimizaci贸n de Hiperpar谩metros (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Optimizar el mejor modelo\n",
    "best_model_name = evaluation_df.iloc[0]['Model']\n",
    "\n",
    "# Ejemplo con Random Forest\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    print(f\"Optimizando hiperpar谩metros para {best_model_name}...\")\n",
    "    print(\"NOTA: Esto puede tomar varios minutos\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Descomentar para ejecutar (puede ser lento)\n",
    "    # grid_search.fit(X_train, y_train)\n",
    "    # print(f\"\\nMejores par谩metros: {grid_search.best_params_}\")\n",
    "    # print(f\"Mejor score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    print(\"\\n锔 Optimizaci贸n comentada para ahorrar tiempo. Descomentar si es necesario.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Discusi贸n de Resultados\n",
    "\n",
    "### 7.1 Resumen de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DE RESULTADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDataset: {df.shape[0]} instancias, {df.shape[1]} caracter铆sticas\")\n",
    "print(f\"Divisi贸n: {len(X_train)} entrenamiento, {len(X_test)} prueba\")\n",
    "print(f\"\\nModelos evaluados: {len(models)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 3 MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "display(evaluation_df.head(3))\n",
    "\n",
    "best_model = evaluation_df.iloc[0]\n",
    "print(f\"\\n MEJOR MODELO: {best_model['Model']}\")\n",
    "print(f\"   - Accuracy: {best_model['Accuracy']:.4f}\")\n",
    "print(f\"   - Precision: {best_model['Precision']:.4f}\")\n",
    "print(f\"   - Recall: {best_model['Recall']:.4f}\")\n",
    "print(f\"   - F1-Score: {best_model['F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 An谩lisis Cr铆tico\n",
    "\n",
    "**Fortalezas del an谩lisis:**\n",
    "- [Menciona los aspectos positivos]\n",
    "- [Qu茅 funcion贸 bien]\n",
    "- [Resultados destacables]\n",
    "\n",
    "**Limitaciones:**\n",
    "- [Limitaciones del dataset]\n",
    "- [Limitaciones de los modelos]\n",
    "- [Posibles sesgos]\n",
    "\n",
    "**Posibles mejoras:**\n",
    "- [T茅cnicas adicionales a probar]\n",
    "- [Feature engineering adicional]\n",
    "- [Optimizaci贸n de hiperpar谩metros]\n",
    "- [Ensemble methods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Interpretaci贸n de Resultados\n",
    "\n",
    "[Discute qu茅 significan los resultados en el contexto del problema original]\n",
    "\n",
    "**Preguntas clave a responder:**\n",
    "1. 驴Los modelos tienen un rendimiento aceptable para el problema?\n",
    "2. 驴Qu茅 caracter铆sticas son m谩s importantes para la predicci贸n?\n",
    "3. 驴Hay evidencia de overfitting o underfitting?\n",
    "4. 驴Los resultados son consistentes con el conocimiento del dominio?\n",
    "5. 驴El modelo es interpretable y explicable?\n",
    "6. 驴Cu谩les son las implicaciones pr谩cticas de los resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusiones\n",
    "\n",
    "### 8.1 Logros Principales\n",
    "\n",
    "- [Conclusi贸n 1]\n",
    "- [Conclusi贸n 2]\n",
    "- [Conclusi贸n 3]\n",
    "\n",
    "### 8.2 Trabajo Futuro\n",
    "\n",
    "- [L铆nea de investigaci贸n 1]\n",
    "- [L铆nea de investigaci贸n 2]\n",
    "- [Mejoras propuestas]\n",
    "\n",
    "### 8.3 Lecciones Aprendidas\n",
    "\n",
    "- [Lecci贸n 1]\n",
    "- [Lecci贸n 2]\n",
    "- [Lecci贸n 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Referencias\n",
    "\n",
    "1. [Referencia del dataset]\n",
    "2. [Documentaci贸n de librer铆as utilizadas]\n",
    "3. [Papers o recursos relevantes]\n",
    "\n",
    "---\n",
    "\n",
    "## Notas Finales\n",
    "\n",
    "**Para compartir en Kaggle:**\n",
    "1. Exporta este notebook\n",
    "2. Incluye el dataset (si es posible)\n",
    "3. A帽ade una descripci贸n clara del problema\n",
    "4. Documenta los resultados\n",
    "\n",
    "**Para el informe (m谩ximo 20 p谩ginas):**\n",
    "- Utiliza las visualizaciones generadas\n",
    "- Resume las tablas de resultados\n",
    "- Enf贸cate en la interpretaci贸n y discusi贸n\n",
    "- Anexa c贸digo relevante si es necesario\n",
    "\n",
    "**Para el video (5 minutos):**\n",
    "- 0:00-0:30: Introducci贸n y contexto\n",
    "- 0:30-1:30: Dataset y an谩lisis descriptivo\n",
    "- 1:30-3:00: Modelos y metodolog铆a\n",
    "- 3:00-4:30: Resultados principales\n",
    "- 4:30-5:00: Conclusiones y trabajo futuro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
